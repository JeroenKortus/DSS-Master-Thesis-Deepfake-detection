{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Xceptionv3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qN03nFN4eyA2"
      },
      "source": [
        "#Google drive authentication"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rV6V8qCHewbj"
      },
      "source": [
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "fid = drive.ListFile({'q':\"title='full_face_data.zip'\"}).GetList()[0]['id']\n",
        "f = drive.CreateFile({'id': fid})\n",
        "f.GetContentFile('full_face_data.zip')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cg5h9onGe4oK"
      },
      "source": [
        "from zipfile import ZipFile\n",
        "import os\n",
        "\n",
        "fileId = 'full_face_data'\n",
        "fileName = fileId + '.zip'\n",
        "ds = ZipFile(fileName)\n",
        "ds.extractall()\n",
        "os.remove(fileName)\n",
        "!rm -rf /content/__MACOSX"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oDXYeFmte--q"
      },
      "source": [
        "#Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "holwzj7qe-UL"
      },
      "source": [
        "import sys\n",
        "import os\n",
        "from keras.layers import *\n",
        "from keras.optimizers import *\n",
        "from keras.applications import *\n",
        "from keras.models import Model\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "from keras import backend as k\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import cv2\n",
        "import glob"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ofQ-4I5WfMEo"
      },
      "source": [
        "#Training the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KghHzavXfOSo"
      },
      "source": [
        "nb_classes = 2  # number of classes\n",
        "based_model_last_block_layer_number = 0 #126  # value is based on based model selected.\n",
        "img_width, img_height = 299, 299  # change based on the shape/structure of your images\n",
        "batch_size = 32  # try 4, 8, 16, 32, 64, 128, 256 dependent on CPU/GPU memory capacity (powers of 2 values).\n",
        "nb_epoch = 20  # number of iteration the algorithm gets trained.\n",
        "transformation_ratio = 0  # how aggressive will be the data augmentation/transformation\n",
        "\n",
        "data_dir = os.path.abspath(\"full_face_data\")\n",
        "train_data_dir = os.path.join(os.path.abspath(data_dir), 'train')  # Inside, each class should have it's own folder\n",
        "validation_data_dir = os.path.join(os.path.abspath(data_dir), 'validation')  # each class should have it's own folder\n",
        "model_path = os.path.abspath(\"model\")\n",
        "\n",
        "os.makedirs(os.path.join(os.path.abspath(data_dir), 'preview'), exist_ok=True)\n",
        "os.makedirs(model_path, exist_ok=True)\n",
        "\n",
        "#train(train_dir, validation_dir, model_dir)\n",
        "\n",
        "base_model = Xception(input_shape=(img_width, img_height, 3), weights='imagenet', include_top=False)\n",
        "\n",
        "# Top Model Block\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "predictions = Dense(nb_classes, activation='softmax')(x)\n",
        "\n",
        "# add your top layer block to your base model\n",
        "model = Model(base_model.input, predictions)\n",
        "\n",
        "# # let's visualize layer names and layer indices to see how many layers/blocks to re-train\n",
        "# # uncomment when choosing based_model_last_block_layer\n",
        "# for i, layer in enumerate(model.layers):\n",
        "#     print(i, layer.name)\n",
        "\n",
        "# first: train only the top layers (which were randomly initialized)\n",
        "# i.e. freeze all layers of the based model that is already pre-trained.\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Read Data and Augment it: Make sure to select augmentations that are appropriate to your images.\n",
        "# To save augmentations un-comment save lines and add to your flow parameters.\n",
        "train_datagen = ImageDataGenerator(rescale=1. / 255,\n",
        "                                    rotation_range=transformation_ratio,\n",
        "                                    shear_range=transformation_ratio,\n",
        "                                    zoom_range=transformation_ratio,\n",
        "                                    cval=transformation_ratio,\n",
        "                                    horizontal_flip=False,\n",
        "                                    vertical_flip=False)\n",
        "\n",
        "validation_datagen = ImageDataGenerator(rescale=1. / 255)\n",
        "\n",
        "os.makedirs(os.path.join(os.path.abspath(train_data_dir), '../preview'), exist_ok=True)\n",
        "train_generator = train_datagen.flow_from_directory(train_data_dir,\n",
        "                                                    target_size=(img_width, img_height),\n",
        "                                                    batch_size=batch_size,\n",
        "                                                    class_mode='categorical')\n",
        "# save_to_dir=os.path.join(os.path.abspath(train_data_dir), '../preview')\n",
        "# save_prefix='aug',\n",
        "# save_format='jpeg')\n",
        "# use the above 3 commented lines if you want to save and look at how the data augmentations look like\n",
        "\n",
        "validation_generator = validation_datagen.flow_from_directory(validation_data_dir,\n",
        "                                                              target_size=(img_width, img_height),\n",
        "                                                              batch_size=batch_size,\n",
        "                                                              class_mode='categorical')\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',  # categorical_crossentropy if multi-class classifier\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# save weights of best training epoch: monitor either val_loss or val_acc\n",
        "\n",
        "top_weights_path = os.path.join(os.path.abspath(model_path), 'top_model_weights.h5')\n",
        "callbacks_list = [\n",
        "    ModelCheckpoint(top_weights_path, monitor='val_accuracy', verbose=1, save_best_only=True),\n",
        "    EarlyStopping(monitor='val_accuracy', patience=5, verbose=0)\n",
        "]\n",
        "\n",
        "# Train Simple CNN\n",
        "model.fit(train_generator,\n",
        "                    steps_per_epoch=train_generator.samples//batch_size,\n",
        "                    epochs=int(nb_epoch / 5),\n",
        "                    validation_data=validation_generator,\n",
        "                    validation_steps=validation_generator.samples//batch_size,\n",
        "                    callbacks=callbacks_list)\n",
        "\n",
        "# verbose\n",
        "print(\"\\nStarting to Fine Tune Model\\n\")\n",
        "\n",
        "# add the best weights from the train top model\n",
        "# at this point we have the pre-train weights of the base model and the trained weight of the new/added top model\n",
        "# we re-load model weights to ensure the best epoch is selected and not the last one.\n",
        "model.load_weights(top_weights_path)\n",
        "\n",
        "# based_model_last_block_layer_number points to the layer in your model you want to train.\n",
        "# For example if you want to train the last block of a 19 layer VGG16 model this should be 15\n",
        "# If you want to train the last Two blocks of an Inception model it should be 172\n",
        "# layers before this number will used the pre-trained weights, layers above and including this number\n",
        "# will be re-trained based on the new data.\n",
        "for layer in model.layers[:based_model_last_block_layer_number]:\n",
        "    layer.trainable = False\n",
        "for layer in model.layers[based_model_last_block_layer_number:]:\n",
        "    layer.trainable = True\n",
        "\n",
        "# compile the model with a SGD/momentum optimizer\n",
        "# and a very slow learning rate.\n",
        "model.compile(optimizer=Adam(learning_rate=0.00001),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy', tf.keras.metrics.AUC()])\n",
        "\n",
        "# save weights of best training epoch: monitor either val_loss or val_acc\n",
        "final_weights_path = os.path.join(os.path.abspath(model_path), 'model_weights.h5')\n",
        "callbacks_list = [\n",
        "    ModelCheckpoint(final_weights_path, monitor='val_accuracy', verbose=1, save_best_only=True),\n",
        "    EarlyStopping(monitor='val_loss', patience=5, verbose=0)\n",
        "]\n",
        "\n",
        "# fine-tune the model\n",
        "model.fit(train_generator,\n",
        "                    steps_per_epoch=train_generator.samples//batch_size,\n",
        "                    epochs=nb_epoch,\n",
        "                    validation_data=validation_generator,\n",
        "                    validation_steps=validation_generator.samples//batch_size,\n",
        "                    callbacks=callbacks_list)\n",
        "\n",
        "# save model\n",
        "model_json = model.to_json()\n",
        "with open(os.path.join(os.path.abspath(model_path), 'model.json'), 'w') as json_file:\n",
        "    json_file.write(model_json)\n",
        "\n",
        "model.load_weights(final_weights_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hJlqaPZ8gV4c"
      },
      "source": [
        "#Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nJ5EtqAMgN7H"
      },
      "source": [
        "val_manipulated = \"full_face_data/validation/manipulated\"\n",
        "val_original = \"full_face_data/validation/original\"\n",
        "man_images = glob.glob(val_manipulated + '/*.bmp')\n",
        "org_images = glob.glob(val_original + '/*.bmp')\n",
        "images = org_images + man_images\n",
        "\n",
        "man_images_len = len(man_images)\n",
        "org_images_len = len(org_images)\n",
        "\n",
        "y_true = [0]*org_images_len + [1]*man_images_len\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "        validation_data_dir,\n",
        "        target_size=(300, 300),\n",
        "\n",
        "        shuffle = False,\n",
        "        class_mode='categorical',\n",
        "        batch_size=1)\n",
        "\n",
        "filenames = test_generator.filenames\n",
        "nb_samples = len(filenames)\n",
        "\n",
        "predict = model.predict_generator(test_generator,steps = nb_samples)\n",
        "\n",
        "y_scores = []\n",
        "for row in predict:\n",
        "  y_scores.append(row[1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vUTZU8fygT9l"
      },
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "AUC = roc_auc_score(y_true, y_scores)\n",
        "print(AUC)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1LqbuHPWgcMQ"
      },
      "source": [
        "from sklearn.metrics import roc_curve\n",
        "fpr, tpr, threshold = roc_curve(y_true, y_scores, pos_label=1)\n",
        "\n",
        "fnr = 1 - tpr\n",
        "eer_threshold = threshold[np.nanargmin(np.absolute((fnr - fpr)))]\n",
        "\n",
        "EER = fpr[np.nanargmin(np.absolute((fnr - fpr)))]\n",
        "check_EER = fnr[np.nanargmin(np.absolute((fnr - fpr)))]\n",
        "\n",
        "print(EER)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}